# Домашнее задание к занятию 6. «Troubleshooting» - Шадрин Алексей

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD-операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести эту операцию:

- напишите список операций, которые вы будете производить для остановки запроса пользователя;

Выведем информацию о свех операциях пользователя username дольше 180 секунд:

```
db.currentOp(
   {
     "active" : true,
     "secs_running" : { "$gt" : 180 },
     "effectiveUsers": {"User" : "username"}
   }
)
```

Завершим операцию:

```
db.killOp(opid)
```


- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB.

*Я бы предложил использовать какой-либо из инструменотов мониторинга (например prometheus), чтобы собирать информацию о медленных запросах. Далее анализировать их с помощью explain и после этого принимать решение - оптимизировать запросы, строить индексы и т.д.*


## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причём отношение количества записанных key-value-значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:

- сначала происходит рост отношения записанных значений к истекшим,
- Redis блокирует операции записи.

Как вы думаете, в чём может быть проблема?

*Вероятно проблема задержках генерируемых истечением срока значений: в redis есть 2 метода удаления истекших значений - lazy и active. Active по умолчанию запускается каждые 100 миллисекунд и удаляет 20 истекших значений. Если после этого процент истекших значений остается больше 25, то механизм запускается еще раз, и так пока процент не снизится ниже 25. При этом redis является однопоточным приложением и в момент удаления не может записывать новые. Таким образом, когда в системе много значений истекающих в одну секунду происходит блокировка на запись. Если перенести это на ситуацию в примере - у нас есть один инстанс redis и к примеру 10 реплик сервиса, которые постоянныо пишут в него новые значения (используя одинаковый механизм ttl), при добавлении 11-ой реплики сперва произойдет рост отношения записанных значений к истекшим, следом redis пойдет удалять истекшие значения, а так как реплики сервиса используют один механизм ttl, то их может быть очень много (>25% от всех в одну секунду) и это вызовет блокировку*

 
## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базы
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения этой проблемы вы можете предложить?

*Судя по тому что проблема начала возникать при росте количества записей в таблицах, дело в долгом выполнении запроса, которое превышет значение таймаута, и соединение обраывается. Первое что я бы сделал - это запустил explain данного запроса и проверил план выполнения. В зависимости от результатов можно было построить дополнительные индексы, либо шардировать большие таблицы.*



## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объёмом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили эту проблему?

*Скорей всего проиходит утечка памяти, из-за чего postmaster вызываетт oom-killer и он убивает наш процесс. Вероятно мы неправильно сконфигурировали сервер postgres, при переводе с mysql. Надо проверить настройки в конфигурационных файлах postgres. В некоторых случаях, в том числе при запуске managed postgres в облаке может помочь уменьшение конфигурационных параметров, связанных с памятью, а именно shared_buffers и work_mem.*